{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e8001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "# from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec, Pinecone\n",
    "import time\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")  # get API key from platform.openai.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a19ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "res = client.embeddings.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2890e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can extract embeddings to a list\n",
    "embeds = [record.embedding for record in res.data]\n",
    "len(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1325fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "\n",
    "index_name = \"ragbot\"\n",
    "\n",
    "# check if index already exists (it shouldn't if this is your first run)\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=len(embeds[0]),  # dimensionality of text-embed-3-small\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4056dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coarse_label': 'DESC', 'fine_label': 'manner', 'text': 'How did serfdom develop in and then leave Russia ?'}\n"
     ]
    }
   ],
   "source": [
    "# trec = load_dataset(\n",
    "#     \"csv\",\n",
    "#     data_files=\"data/train_5500.label\",\n",
    "#     split=\"train[:1000]\",\n",
    "# )\n",
    "data = []\n",
    "with open(\"data/train_5500.label\", \"r\", encoding=\"latin1\") as f:\n",
    "    for line in f:\n",
    "        label, question = line.strip().split(\" \", 1)\n",
    "        coarse_label, fine_label = label.split(\":\")\n",
    "        data.append({\n",
    "            \"coarse_label\": coarse_label,\n",
    "            \"fine_label\": fine_label,\n",
    "            \"text\": question\n",
    "        })\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "trec = Dataset.from_list(data)\n",
    "\n",
    "# Optional: take the first 1000\n",
    "trec = trec.select(range(min(1000, len(trec))))\n",
    "\n",
    "# Check\n",
    "print(trec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4657e890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0c546877b74ab7ac7fa4c5aeeec332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "count = 0  # we'll use the count to create unique IDs\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(trec['text']), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(trec['text']))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = trec['text'][i: i+batch_size]\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    res = client.embeddings.create(input=lines_batch, model=MODEL)\n",
    "    embeds = [record.embedding for record in res.data]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1a9d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What caused the 1929 Great Depression?\"\n",
    "\n",
    "xq = client.embeddings.create(input=query, model=MODEL).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0dba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = index.query(vector = [xq], top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "301729b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75: Why did the world enter a global depression in 1929 ?\n",
      "0.60: When was `` the Great Depression '' ?\n",
      "0.37: What crop failure caused the Irish Famine ?\n",
      "0.32: What were popular songs and types of songs in the 1920s ?\n",
      "0.32: When did World War I start ?\n"
     ]
    }
   ],
   "source": [
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7063c",
   "metadata": {},
   "source": [
    "#### Harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66db6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63: Why did the world enter a global depression in 1929 ?\n",
      "0.55: When was `` the Great Depression '' ?\n",
      "0.34: What were popular songs and types of songs in the 1920s ?\n",
      "0.33: What crop failure caused the Irish Famine ?\n",
      "0.29: What is considered the costliest disaster the insurance industry has ever faced ?\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the cause of the major recession in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = client.embeddings.create(input=query, model=MODEL).data[0].embedding\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query(vector=[xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecd515d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62: Why did the world enter a global depression in 1929 ?\n",
      "0.54: When was `` the Great Depression '' ?\n",
      "0.34: What were popular songs and types of songs in the 1920s ?\n",
      "0.33: What crop failure caused the Irish Famine ?\n",
      "0.32: What do economists do ?\n"
     ]
    }
   ],
   "source": [
    "query = \"Why was there a long-term economic downturn in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = client.embeddings.create(input=query, model=MODEL).data[0].embedding\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query(vector=[xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5634a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
